{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:00:48.385696Z",
     "start_time": "2024-03-27T06:00:44.676994Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gzip, os, sys\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_mnist_images(filename):\n",
    "    # if not os.path.exists(filename):\n",
    "    #     download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "# 加载标签\n",
    "def load_mnist_labels(filename): \n",
    "    # if not os.path.exists(filename):\n",
    "    #     download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:00:54.507219Z",
     "start_time": "2024-03-27T06:00:54.503490Z"
    }
   },
   "id": "e6a060f5794cb443",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:01:02.847803Z",
     "start_time": "2024-03-27T06:01:02.632954Z"
    }
   },
   "id": "d64dc923a2c3a3b2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:02:13.751047Z",
     "start_time": "2024-03-27T06:02:13.747789Z"
    }
   },
   "id": "3cbc1ba5b57df0f0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def show_digit(x, label):\n",
    "     plt.axis('off')\n",
    "     plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "     plt.title('Label ' + str(label))\n",
    "     plt.show()\n",
    "     return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:05:41.937652Z",
     "start_time": "2024-03-27T06:05:41.933622Z"
    }
   },
   "id": "80d4a983d2809b4f",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build data structure (seconds):  0.025021076202392578\n",
      "Time to classify test set (seconds):  0.0020036697387695312\n",
      "accuracy:  0.07\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10000, 100]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 33\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msn\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m metrics\n\u001B[1;32m---> 33\u001B[0m cm \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39mconfusion_matrix(test_labels,test_predictions)\n\u001B[0;32m     34\u001B[0m df_cm \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(cm, \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m), \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m))\n\u001B[0;32m     35\u001B[0m sn\u001B[38;5;241m.\u001B[39mset(font_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.2\u001B[39m)\u001B[38;5;66;03m# for label size\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:319\u001B[0m, in \u001B[0;36mconfusion_matrix\u001B[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001B[0m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m    225\u001B[0m     {\n\u001B[0;32m    226\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    235\u001B[0m     y_true, y_pred, \u001B[38;5;241m*\u001B[39m, labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    236\u001B[0m ):\n\u001B[0;32m    237\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001B[39;00m\n\u001B[0;32m    238\u001B[0m \n\u001B[0;32m    239\u001B[0m \u001B[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;124;03m    (0, 2, 1, 1)\u001B[39;00m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 319\u001B[0m     y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m y_type)\n",
      "File \u001B[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_targets\u001B[39m(y_true, y_pred):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \n\u001B[0;32m     61\u001B[0m \u001B[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;124;03m    y_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m     check_consistent_length(y_true, y_pred)\n\u001B[0;32m     86\u001B[0m     type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     87\u001B[0m     type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\pytorch\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    455\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    459\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    460\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [10000, 100]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neighbors import BallTree\n",
    "## Build nearest neighbor structure on training data\n",
    "t_before = time.time()\n",
    "ball_tree = BallTree(train_data[3000:4000,:])\n",
    "t_after = time.time()\n",
    "# Compute training time\n",
    "t_training = t_after - t_before\n",
    "print(\"Time to build data structure (seconds): \", t_training)\n",
    "## Get nearest neighbor predictions on testing data\n",
    "test_data1=test_data[500,:]\n",
    "test_labels1=test_labels[500]\n",
    "\n",
    "t_before = time.time()\n",
    "test_data1 = np.expand_dims(test_data1,0)\n",
    "test_neighbors = ball_tree.query(test_data1, k=100, return_distance=False)\n",
    "test_neighbors = np.squeeze(test_neighbors)\n",
    "# test_neighbors = np.squeeze(ball_tree.query(test_data1, k=1, return_distance=False))\n",
    "test_predictions = train_labels[test_neighbors]\n",
    "t_after = time.time()\n",
    "## Compute testing time\n",
    "t_testing = t_after - t_before\n",
    "print(\"Time to classify test set (seconds): \", t_testing)\n",
    "# evaluate the classifier\n",
    "t_accuracy = sum(test_predictions == test_labels1) / 100 #float(len(test_labels1))\n",
    "# t_accuracy\n",
    "print(\"accuracy: \", t_accuracy)\n",
    "0.96909999999999996\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(test_labels,test_predictions)\n",
    "df_cm = pd.DataFrame(cm, range(10), range(10))\n",
    "sn.set(font_scale=1.2)# for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt=\"g\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:09:51.482451Z",
     "start_time": "2024-03-27T06:09:47.576636Z"
    }
   },
   "id": "fd08ef5d67c9785b",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cb50ca882697f9e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
